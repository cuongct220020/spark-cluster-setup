# Spark High Availability Cluster v·ªõi ZooKeeper

C·ª•m Spark Standalone v·ªõi High Availability s·ª≠ d·ª•ng ZooKeeper cho master election v√† failover t·ª± ƒë·ªông.

## Ki·∫øn tr√∫c

### ZooKeeper Cluster (3 nodes)
- `zookeeper-1`: Port 2181
- `zookeeper-2`: Port 2182  
- `zookeeper-3`: Port 2183

### Spark Master Cluster (3 nodes)
- `spark-master-1`: Port 7077 (Spark), 8080 (Web UI) - **ACTIVE ho·∫∑c STANDBY**
- `spark-master-2`: Port 7078 (Spark), 8081 (Web UI) - **ACTIVE ho·∫∑c STANDBY**
- `spark-master-3`: Port 7079 (Spark), 8082 (Web UI) - **ACTIVE ho·∫∑c STANDBY**

### Spark Workers (3 nodes)
- `spark-worker-1`: Port 8083 (Web UI)
- `spark-worker-2`: Port 8084 (Web UI)
- `spark-worker-3`: Port 8085 (Web UI)

## Kh·ªüi ƒë·ªông c·ª•m

```bash
# Kh·ªüi ƒë·ªông to√†n b·ªô cluster
docker-compose up -d

# Xem logs
docker-compose logs -f

# Ki·ªÉm tra tr·∫°ng th√°i
docker-compose ps
```

## Ki·ªÉm tra tr·∫°ng th√°i

### 1. Ki·ªÉm tra ZooKeeper Cluster

```bash
# Ki·ªÉm tra ZooKeeper node 1
docker exec -it zookeeper-1 zkServer.sh status

# Ki·ªÉm tra ZooKeeper node 2
docker exec -it zookeeper-2 zkServer.sh status

# Ki·ªÉm tra ZooKeeper node 3
docker exec -it zookeeper-3 zkServer.sh status
```

K·∫øt qu·∫£ s·∫Ω hi·ªÉn th·ªã: **leader** (1 node) v√† **follower** (2 nodes)

### 2. Ki·ªÉm tra Spark Master Status

Truy c·∫≠p Web UI c·ªßa c√°c Master:
- http://localhost:8080 (Master 1)
- http://localhost:8081 (Master 2)
- http://localhost:8082 (Master 3)

Ch·ªâ c√≥ **1 Master** hi·ªÉn th·ªã status **ALIVE** (active), c√°c Master kh√°c s·∫Ω hi·ªÉn th·ªã **STANDBY**.

### 3. Ki·ªÉm tra Spark Workers

Workers ch·ªâ hi·ªÉn th·ªã tr√™n Web UI c·ªßa **Active Master**.

## Submit Spark Application

### C√∫ ph√°p submit v·ªõi HA

```bash
docker exec -it spark-master-1 spark-submit \
  --master spark://spark-master-1:7077,spark-master-2:7077,spark-master-3:7077 \
  --deploy-mode cluster \
  --class org.apache.spark.examples.SparkPi \
  /opt/spark/examples/jars/spark-examples_2.12-3.5.0.jar \
  1000
```

### V√≠ d·ª• v·ªõi Python

```bash
docker exec -it spark-master-1 spark-submit \
  --master spark://spark-master-1:7077,spark-master-2:7077,spark-master-3:7077 \
  --deploy-mode client \
  /path/to/your/script.py
```

### Supervised Mode (Driver t·ª± ƒë·ªông restart)

```bash
docker exec -it spark-master-1 spark-submit \
  --master spark://spark-master-1:7077,spark-master-2:7077,spark-master-3:7077 \
  --deploy-mode cluster \
  --supervise \
  --class YourMainClass \
  /path/to/your/app.jar
```

## Test Failover

### Test 1: Kill Active Master

```bash
# X√°c ƒë·ªãnh Master n√†o ƒëang ACTIVE (v√≠ d·ª•: spark-master-1)
docker stop spark-master-1

# Ch·ªù 10-20 gi√¢y v√† ki·ªÉm tra
# M·ªôt trong hai Master c√≤n l·∫°i s·∫Ω tr·ªü th√†nh ACTIVE
# Workers v√† applications ƒëang ch·∫°y s·∫Ω t·ª± ƒë·ªông reconnect
```

Ki·ªÉm tra logs:
```bash
docker logs spark-master-2 | tail -20
docker logs spark-worker-1 | tail -20
```

B·∫°n s·∫Ω th·∫•y:
- Master 2 ho·∫∑c 3: `I have been elected leader! New state: ALIVE`
- Workers: `Master has changed, new master is at spark://...`

### Test 2: Kill ZooKeeper Node

```bash
# Kill 1 trong 3 ZooKeeper nodes
docker stop zookeeper-1

# Cluster v·∫´n ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng (quorum = 2/3)
# Spark Master v·∫´n ho·∫°t ƒë·ªông

# Kill th√™m 1 node n·ªØa (quorum m·∫•t)
docker stop zookeeper-2

# Cluster kh√¥ng th·ªÉ election Master m·ªõi
# Nh∆∞ng Master hi·ªán t·∫°i v·∫´n ho·∫°t ƒë·ªông
```

### Test 3: Restart Master ƒë√£ kill

```bash
# Restart Master ƒë√£ stop
docker start spark-master-1

# Master 1 s·∫Ω kh·ªüi ƒë·ªông l·∫°i ·ªü ch·∫ø ƒë·ªô STANDBY
```

## Troubleshooting

### Ki·ªÉm tra logs chi ti·∫øt

```bash
# ZooKeeper logs
docker logs zookeeper-1
docker logs zookeeper-2
docker logs zookeeper-3

# Spark Master logs
docker logs spark-master-1
docker logs spark-master-2
docker logs spark-master-3

# Spark Worker logs
docker logs spark-worker-1
docker logs spark-worker-2
docker logs spark-worker-3
```

### Ki·ªÉm tra ZooKeeper data

```bash
# K·∫øt n·ªëi v√†o ZooKeeper CLI
docker exec -it zookeeper-1 zkCli.sh

# Trong CLI, ki·ªÉm tra Spark HA data
ls /spark-ha
get /spark-ha/master_status
```

### Reset cluster

```bash
# D·ª´ng v√† x√≥a t·∫•t c·∫£ containers
docker-compose down

# X√≥a volumes (n·∫øu c·∫ßn reset ho√†n to√†n)
docker-compose down -v

# Kh·ªüi ƒë·ªông l·∫°i
docker-compose up -d
```

## C·∫•u h√¨nh t√πy ch·ªânh

### Thay ƒë·ªïi t√†i nguy√™n Worker

Ch·ªânh s·ª≠a trong `docker-compose.yml`:

```yaml
environment:
  - SPARK_WORKER_CORES= ${SPARK_WORKER_CORES}     # TƒÉng s·ªë cores
  - SPARK_WORKER_MEMORY= ${SPARK_WORKER_MEMORY}   # TƒÉng memory
```

### Th√™m Workers

Th√™m service m·ªõi v√†o `docker-compose.yml`:

```yaml
spark-worker-4:
  image: apache/spark:3.5.0
  container_name: spark-worker-4
  # ... t∆∞∆°ng t·ª± worker kh√°c
```

### Enable Security (n·∫øu c·∫ßn)

Uncomment c√°c d√≤ng security trong file docker-compose:

```yaml
# - SPARK_RPC_AUTHENTICATION_ENABLED=yes
# - SPARK_RPC_AUTHENTICATION_SECRET=devsecret
# - SPARK_RPC_ENCRYPTION_ENABLED=yes
```

## Monitoring

### ZooKeeper Metrics

```bash
# Ki·ªÉm tra tr·∫°ng th√°i
echo stat | nc localhost 2181

# Ki·ªÉm tra config
echo conf | nc localhost 2181

# Ki·ªÉm tra connections
echo cons | nc localhost 2181
```

### Spark Metrics

Truy c·∫≠p Web UI:
- Active Master: http://localhost:8080
- Worker 1: http://localhost:8083
- Worker 2: http://localhost:8084
- Worker 3: http://localhost:8085

## D·ª´ng cluster

```bash
# D·ª´ng t·∫•t c·∫£ services
docker-compose down

# D·ª´ng v√† x√≥a volumes
docker-compose down -v
```

## üìö Tham kh·∫£o

- [Spark Standalone Mode](https://spark.apache.org/docs/latest/spark-standalone.html)
- [Spark High Availability](https://spark.apache.org/docs/latest/spark-standalone.html#high-availability)
- [ZooKeeper Documentation](https://zookeeper.apache.org/doc/current/)

## ‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng

1. **Production Setup**: Trong production, n√™n deploy ZooKeeper v√† Spark tr√™n c√°c m√°y v·∫≠t l√Ω kh√°c nhau
2. **Network**: ƒê·∫£m b·∫£o network latency th·∫•p gi·ªØa c√°c nodes
3. **Resources**: ZooKeeper c·∫ßn √≠t t√†i nguy√™n, nh∆∞ng Spark Master c·∫ßn memory ƒë·ªß l·ªõn
4. **Backup**: Backup ZooKeeper data directory ƒë·ªãnh k·ª≥
5. **Monitoring**: S·ª≠ d·ª•ng monitoring tools (Prometheus, Grafana) cho production